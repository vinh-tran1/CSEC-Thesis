{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: \n",
    "- Startup Description\n",
    "- Founder Description\n",
    "- Industry Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# python -m textblob.download_corpora\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUGGING FACE TOKEN\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_CLI_TOKEN\")\n",
    "\n",
    "# FOLDERS\n",
    "OUTPUT_FOLDER = \"../Data/Output\"\n",
    "INPUT_FOLDER = \"../Data/Input\"\n",
    "\n",
    "OUTPUT_CB_FOLDER = os.path.join(OUTPUT_FOLDER, \"Crunchbase\")\n",
    "OUTPUT_NLP_FOLDER = os.path.join(OUTPUT_FOLDER, \"NLP\")\n",
    "CHECKPOINT_NLP_FOLDER = os.path.join(OUTPUT_FOLDER, \"Checkpoint\")\n",
    "\n",
    "checkpoint_path = os.path.join(OUTPUT_NLP_FOLDER, \"nlp_checkpoint.jsonl\")\n",
    "outlook_checkpoint_path = os.path.join(OUTPUT_NLP_FOLDER, \"nlp_outlook_checkpoint.csv\")\n",
    "sentiment_score_path = os.path.join(OUTPUT_NLP_FOLDER, \"nlp_sentiment_features.csv\")\n",
    "\n",
    "output_contents_cb = os.listdir(OUTPUT_CB_FOLDER)\n",
    "output_contents_nlp = os.listdir(OUTPUT_NLP_FOLDER)\n",
    "\n",
    "print(output_contents_cb)\n",
    "print(output_contents_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df_path = os.path.join(OUTPUT_NLP_FOLDER, \"perplexity.csv\")\n",
    "nlp_scores_path = os.path.join(OUTPUT_NLP_FOLDER, \"alignment_scores_v2.jsonl\")\n",
    "cb_df_path = os.path.join(OUTPUT_CB_FOLDER, \"cb_final_data.csv\")\n",
    "nlp_founder_df = os.path.join(OUTPUT_NLP_FOLDER, \"founder_strength_scores.jsonl\")\n",
    "\n",
    "cb_df = pd.read_csv(cb_df_path)\n",
    "nlp_df = pd.read_csv(nlp_df_path)\n",
    "alignment_df = pd.read_json(nlp_scores_path, lines=True)\n",
    "nlp_founder_df = pd.read_json(nlp_founder_df, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_df.info()\n",
    "print()\n",
    "nlp_df.info()\n",
    "print()\n",
    "alignment_df.info()\n",
    "print()\n",
    "nlp_founder_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup + Founder Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 1. Load Models\n",
    "# ==========================\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "finbert_sentiment = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "founder_sentiment = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "bert_embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 2. Scoring Functions\n",
    "# ==========================\n",
    "\n",
    "def get_textblob_scores(text):\n",
    "    \"\"\"Returns polarity and subjectivity from TextBlob.\"\"\"\n",
    "    if not isinstance(text, str): return {\"polarity\": None, \"subjectivity\": None}\n",
    "    blob = TextBlob(text)\n",
    "    return {\n",
    "        \"polarity\": blob.sentiment.polarity,\n",
    "        \"subjectivity\": blob.sentiment.subjectivity\n",
    "    }\n",
    "\n",
    "def get_vader_scores(text):\n",
    "    \"\"\"Returns compound and sub-scores from VADER.\"\"\"\n",
    "    if not isinstance(text, str): return {\"compound\": None, \"pos\": None, \"neg\": None, \"neu\": None}\n",
    "    return vader.polarity_scores(text)\n",
    "\n",
    "def get_finbert_score(text):\n",
    "    \"\"\"Returns FinBERT sentiment score (5-scale and signed).\"\"\"\n",
    "    if not isinstance(text, str): return {\"label\": None, \"score\": None, \"numeric_5scale\": None, \"numeric_signed\": None}\n",
    "    result = finbert_sentiment(text[:512])[0]\n",
    "    label_map_5 = {\"positive\": 5, \"neutral\": 3, \"negative\": 1}\n",
    "    label_map_signed = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "    label = result['label'].lower()\n",
    "    return {\n",
    "        # \"label\": result['label'],\n",
    "        # \"score\": result['score'],\n",
    "        \"numeric_5scale\": label_map_5.get(label),\n",
    "        \"numeric_signed\": label_map_signed.get(label)\n",
    "    }\n",
    "\n",
    "def get_founder_sentiment_score(text):\n",
    "    \"\"\"Returns founder sentiment score using CardiffNLP.\"\"\"\n",
    "    if not isinstance(text, str): return {\"label\": None, \"score\": None, \"numeric_5scale\": None, \"numeric_signed\": None}\n",
    "    result = founder_sentiment(text[:512])[0]\n",
    "    label_map_5 = {\n",
    "        \"POS\": 5, \"NEU\": 3, \"NEG\": 1,\n",
    "        \"LABEL_2\": 5, \"LABEL_1\": 3, \"LABEL_0\": 1\n",
    "    }\n",
    "    label_map_signed = {\n",
    "        \"POS\": 1, \"NEU\": 0, \"NEG\": -1,\n",
    "        \"LABEL_2\": 1, \"LABEL_1\": 0, \"LABEL_0\": -1\n",
    "    }\n",
    "    label = result['label'].upper()\n",
    "    return {\n",
    "        # \"label\": result['label'],\n",
    "        # \"score\": result['score'],\n",
    "        \"numeric_5scale\": label_map_5.get(label),\n",
    "        \"numeric_signed\": label_map_signed.get(label)\n",
    "    }\n",
    "\n",
    "def get_bert_similarity(text, exemplar_vector):\n",
    "    \"\"\"Returns cosine similarity to exemplar startup vector.\"\"\"\n",
    "    if not isinstance(text, str): return None\n",
    "    emb = bert_embedder.encode(text, convert_to_tensor=True)\n",
    "    sim = util.cos_sim(emb, exemplar_vector).item()\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3. Checkpoint Handling\n",
    "# ==========================\n",
    "def load_checkpoint(path):\n",
    "    if not os.path.exists(path):\n",
    "        return set(), []\n",
    "    seen_ids = set()\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = [json.loads(line) for line in f if line.strip()]\n",
    "        for row in lines:\n",
    "            seen_ids.add(row[\"org_uuid\"])\n",
    "    return seen_ids, lines\n",
    "\n",
    "def save_checkpoint(path, results):\n",
    "    with open(path, \"a\") as f:\n",
    "        for row in results:\n",
    "            f.write(json.dumps(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4. Exemplar Setup\n",
    "# ==========================\n",
    "startup_exemplars = [\n",
    "    \"Instagram is a free photosharing application that enables its users to take photos apply filters and share them on social networks such as Facebook Twitter Foursquare Tumblr Flickr and Posterous The app allows its users to capture and customize their photos and videos with several custombuilt filter effects It is also compatible with iOS and Android devices Instagram was founded by Kevin Systrom and Mike Krieger in 2010 in San Francisco California\",\n",
    "    \"Stripe is a technology company that builds economic infrastructure for the Internet Stripe is a platform for commercial finance infrastructure Stripe is used by millions of businesses ranging from the biggest corporations in the world to the most ambitious startups to take payments increase revenue and open up new business prospects\",\n",
    "    \"Airbnb operates an online platform that connects hosts with guests seeking shortterm accommodations The company facilitates bookings and provides tools for both parties to manage their transactions Airbnb focuses on various types of lodging including homes and unique stays\",\n",
    "    \"Uber develops and operates a ridesharing mobile application that connects consumers with partner drivers The application allows users to submit trip requests which are then routed to available drivers It facilitates the arrangement and scheduling of transportation and logistics services through thirdparty providers Uber operates in various cities worldwide providing applications for multiple platforms including Windows Phone iPhone Blackberry and Android\",\n",
    "    \"Liquid Death is the first bold hilarious beverage focused on health and sustainability and it is one of the fastestgrowing nonalcoholic beverage brands of all time They take the healthiest beverage available water and package it in infinitely recyclable tallboy cans that can compete with the fun marketing of unhealthy brands in energy drinks beer and junk food In addition Liquid Death donates 10 of its profits from each can sold to nonprofits that work to eliminate plastic pollution and provide clean drinking water to those in need\",\n",
    "    \"WhatsApp is a crossplatform mobile messaging app that allows users to exchange messages without paying for SMS WhatsApp Messenger is available for iPhone Blackberry Android Windows Phone Nokia and Symbian platforms Since WhatsApp Messenger uses the same internet data plan that subscribers use for email and web browsing there is no cost to message allowing them to stay in touch with their friends In addition to basic messaging WhatsApp users can create groups and send each other unlimited images video and audio media messages\",\n",
    "    \"Moderna Therapeutics is a biotechnology company that develops messenger RNA therapeutics Every cell in the body uses mRNA to provide realtime instructions to make the proteins necessary to drive all aspects of biology including in human health and disease It provides in vivo drug modality that produces human proteins or antibodies inside patient cells  Moderna Therapeutics also develops various patent applications with various claims ranging from novel nucleotide chemistries to specific drug compositions It focuses on disease areas such as inherited genetic disorders hemophilia and blood factors and oncology  Moderna Therapeutics in 2010 and is headquartered in Cambridge in Massachusetts It has strategic option agreements with AstraZeneca and Alexion Pharmaceuticals and strategic collaborations with Karolinska Institutet Institut Pasteur Karolinska University Hospital and Merck\",\n",
    "    \"Roblox is a platform for online gaming and entertainment that provides a communal digital experience that unites individuals via play It enables anyone to imagine create and have fun with friends as they explore interactive 3D experiences produced by developers using their desktop design tool Roblox Studio\",\n",
    "    \"Waymo stands for a new way forward in mobility it is a selfdriving technology company with a mission to make it safe and easy for people and things to move around Waymo improves transportation by building software and sensor technology developed in Googles labs since 2009 In October 2015 they achieved the worlds first fully selfdriving trip on public roads in a car without a steering wheel or pedals They refine Waymo technology through one billion miles of simulation testing each year and the cars have selfdriven over two million miles on public roads across four US cities\",\n",
    "    \"Brimstone developed a deeply decarbonized process to make ordinary portland cement and another key concrete ingredient supplementary cementitious material The Brimstone Process uses carbonfree calcium silicate rock instead of limestone to deliver a product that is identical to conventional materials and costcompetitive at scale\",\n",
    "    \"Suno is a music startup that enables anyone to make the songs they want The company aims to help people rediscover the joy of play and exploration\",\n",
    "    \"Snappr is the onestopshop for visual content creation including the largest ondemand photography and photo editing marketplace Snappr Shoots is a selfservice application to book photographers Snappr Workflows is a SaaS product for enterprises to automate their visual content pipeliness Snappr also provides free tools such as the Snappr Photo Analyzer an AI portrait photoanalysis tool Snappr was founded in 2017 and is headquartered in San Francisco California\"\n",
    "]\n",
    "startup_exemplar_vector = bert_embedder.encode(startup_exemplars, convert_to_tensor=True).mean(dim=0)\n",
    "\n",
    "founder_blob_1 = \"Erik Hazzard is the Founder of Meta Erik Hazzard attended Florida State University Andrew Gadson is the Founder  New Product Experimentation of Meta He attended Stanford University Mike LeBeau is a Founder and Product Lead Horizon Workrooms at Meta He attended Stanford University Mark Zuckerberg is the Founder Chairman and Chief Executive Officer of Facebook He is also the CoFounder of the Breakthrough Energy Coalition Mr Zuckerberg attended Harvard University Eduardo Saverin is a Cofounder at Meta Eduardo attended Harvard University\"\n",
    "founder_blob_2 = \"Elon Musk has cofounded companies such as SpaceX and tunneling startup The Boring Company and has played served as CEO of Tesla Motors since 2008 He previously worked as a sales manager at many enterprise LLCs Elon Musk attended the University of Pennsylvania and received bachelors degrees in economics and physics\"\n",
    "founder_blob_3 = \"Max Levchin is the Founder and CEO of Affirm He previously worked at the Consumer Financial Protection Bureau as an Advisory Board Member Max Levchin attended the University of Illinois UrbanaChampaign\"\n",
    "founder_blob_4 = \"Peter Thiel Is the Managing Partner of The Founders Fund He previously worked at Stanford Law School as a Visitor Peter Thiel attended Stanford University\"\n",
    "founder_blob_5 = \"John Collison is a President and Cofounder at Stripe He attended Harvard University John and his brother Patrick Collison started Stripe in 2010 while John was studying physics at Harvard Their goal was to make accepting payments online simpler and more inclusive after learning firsthand how difficult it was Today the 100 person and growing Stripe team powers online businesses around the world Before Stripe John cofounded Auctomatic which was acquired by Live Current Media in March 2008 Originally from Limerick Ireland John lives in San Francisco California where Stripe is based Patrick Collison is the CoFounder CEO and Content Strategist of Stripe He previously worked at Auctomatic as a CoFounder Patrick Collison attended Massachusetts Institute of Technology\"\n",
    "founder_blob_6 = \"Kevin is the CEO and cofounder of Instagram a community of more than 300 million who capture and share the worlds moments on the service He is responsible for the companys overall vision and strategy as well as daytoday operations   Prior to founding Instagram Kevin was part of the startup Odeo which later became Twitter and spent two years at Google working on products such as Gmail and Google Reader He graduated from Stanford University with a bachelor of science in management science and engineering\"\n",
    "founder_blob_7 = \"Nathan Blecharczyk is the CoFounder and Chief Strategy Officer at Airbnb a trusted community marketplace that connects people with unique accommodations in more than 34000 cities and 191 countries Blecharczyk oversaw the creation of Airbnbs engineering data science and performance marketing teams and currently plays a leading role in the companys business and product strategy He became an entrepreneur early on running a business while he was in high school that sold to clients in more than 20 countries He earned a degree in Computer Science from Harvard University and held several engineering positions before cofounding Airbnb As a guest Blecharczyk has stayed in hundreds of homes using Airbnb and he is also a host in San Francisco where he lives with his family Joe Gebbia is a CoFounder and Chairman of Airbnb An entrepreneur from an early age Airbnbs groundbreaking service began in his San Francisco apartment and spread to 2000000 listings in over 191 countries creating a new economy for thousands of people around the world He is involved in crafting the company culture shaping the design aesthetic and innovating future growth opportunities Joe has spoken globally about both entrepreneurship and design and received numerous distinctions such as the Inc 30 under 30 and Fortune 40 under 40 His lifelong appreciation for art and design led him to the Rhode Island School of Design RISD where he earned dual degrees in Graphic Design and Industrial Design Gebbia now serves on the institutions Board of Trustees Brian is the CoFounder and Chief Executive Officer at Airbnb He attended Rhode Island School of Design\"\n",
    "\n",
    "founder_exmplars = [\n",
    "    founder_blob_1,\n",
    "    founder_blob_2,\n",
    "    founder_blob_3,\n",
    "    founder_blob_4,\n",
    "    founder_blob_5,\n",
    "    founder_blob_6,\n",
    "    founder_blob_7\n",
    "]\n",
    "founder_exemplar_vector = bert_embedder.encode(founder_exmplars, convert_to_tensor=True).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4. Main Scoring Function\n",
    "# ==========================\n",
    "def score_descriptions_with_checkpoint(df, startup_exemplar_vector, founder_exemplar_vector,\n",
    "                                    checkpoint_path=checkpoint_path, batch_size=25):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame and appends results to checkpoint every N rows.\n",
    "    Resumes if checkpoint already exists.\n",
    "    \"\"\"\n",
    "    seen_ids, saved_rows = load_checkpoint(checkpoint_path)\n",
    "    new_results = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        if row[\"org_uuid\"] in seen_ids:\n",
    "            continue\n",
    "\n",
    "        org_text = row.get(\"org_description\", \"\")\n",
    "        founder_text = row.get(\"founder_description_blob\", \"\")\n",
    "\n",
    "        # --- Startup Scoring ---\n",
    "        org_vader = get_vader_scores(org_text)\n",
    "        org_blob = get_textblob_scores(org_text)\n",
    "        org_finbert = get_finbert_score(org_text)\n",
    "        org_sim = get_bert_similarity(org_text, startup_exemplar_vector)\n",
    "\n",
    "        # --- Founder Scoring ---\n",
    "        founder_vader = get_vader_scores(founder_text)\n",
    "        founder_blob = get_textblob_scores(founder_text)\n",
    "        founder_bert = get_founder_sentiment_score(founder_text)\n",
    "        founder_sim = get_bert_similarity(founder_text, founder_exemplar_vector)\n",
    "\n",
    "        result = {\n",
    "            \"org_uuid\": row[\"org_uuid\"],\n",
    "            \"org_name\": row[\"org_name\"],\n",
    "\n",
    "            \"org_vader_compound\": org_vader[\"compound\"],\n",
    "            \"org_vader_pos\": org_vader[\"pos\"],\n",
    "            \"org_vader_neg\": org_vader[\"neg\"],\n",
    "            \"org_vader_neu\": org_vader[\"neu\"],\n",
    "            \"org_blob_polarity\": org_blob[\"polarity\"],\n",
    "            \"org_blob_subjectivity\": org_blob[\"subjectivity\"],\n",
    "            # \"org_finbert_label\": org_finbert[\"label\"],\n",
    "            # \"org_finbert_score\": org_finbert[\"score\"],\n",
    "            \"org_finbert_numeric_5scale\": org_finbert[\"numeric_5scale\"],\n",
    "            \"org_finbert_numeric_signed\": org_finbert[\"numeric_signed\"],\n",
    "            \"org_sim_to_exemplar\": org_sim,\n",
    "\n",
    "            \"founder_vader_compound\": founder_vader[\"compound\"],\n",
    "            \"founder_vader_pos\": founder_vader[\"pos\"],\n",
    "            \"founder_vader_neg\": founder_vader[\"neg\"],\n",
    "            \"founder_vader_neu\": founder_vader[\"neu\"],\n",
    "            \"founder_blob_polarity\": founder_blob[\"polarity\"],\n",
    "            \"founder_blob_subjectivity\": founder_blob[\"subjectivity\"],\n",
    "            # \"founder_sentiment_label\": founder_bert[\"label\"],\n",
    "            # \"founder_sentiment_score\": founder_bert[\"score\"],\n",
    "            \"founder_sentiment_numeric_5scale\": founder_bert[\"numeric_5scale\"],\n",
    "            \"founder_sentiment_numeric_signed\": founder_bert[\"numeric_signed\"],\n",
    "            \"founder_sim_to_exemplar\": founder_sim\n",
    "        }\n",
    "\n",
    "        new_results.append(result)\n",
    "\n",
    "        if len(new_results) >= batch_size:\n",
    "            save_checkpoint(checkpoint_path, new_results)\n",
    "            new_results = []\n",
    "\n",
    "    if new_results:\n",
    "        save_checkpoint(checkpoint_path, new_results)\n",
    "\n",
    "    return pd.DataFrame(saved_rows + new_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "scored_df = score_descriptions_with_checkpoint(\n",
    "    df=cb_df,\n",
    "    startup_exemplar_vector=startup_exemplar_vector,\n",
    "    founder_exemplar_vector=founder_exemplar_vector,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    batch_size=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_json(checkpoint_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for training or merging\n",
    "sentiment_df.to_csv(sentiment_score_path, index=False)\n",
    "print(f\"Saved to {sentiment_score_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finbert():\n",
    "    model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    return tokenizer, model\n",
    "\n",
    "def finbert_score(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "    return dict(zip(labels, probs[0].tolist()))\n",
    "\n",
    "def analyze_text(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\n",
    "            \"vader_neg\": None, \"vader_neu\": None, \"vader_pos\": None, \"vader_compound\": None,\n",
    "            \"textblob_polarity\": None, \"textblob_subjectivity\": None\n",
    "        }\n",
    "    vader = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    blob = TextBlob(text)\n",
    "    return {\n",
    "        \"vader_neg\": vader[\"neg\"],\n",
    "        \"vader_neu\": vader[\"neu\"],\n",
    "        \"vader_pos\": vader[\"pos\"],\n",
    "        \"vader_compound\": vader[\"compound\"],\n",
    "        \"textblob_polarity\": blob.sentiment.polarity,\n",
    "        \"textblob_subjectivity\": blob.sentiment.subjectivity\n",
    "    }\n",
    "\n",
    "def score_nlp_df(nlp_df, checkpoint_path=outlook_checkpoint_path, batch_size=25):\n",
    "    tokenizer, model = load_finbert()\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        df_checkpoint = pd.read_csv(checkpoint_path)\n",
    "        start_idx = len(df_checkpoint)\n",
    "        results = df_checkpoint.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        start_idx = 0\n",
    "        results = []\n",
    "\n",
    "    for i in tqdm(range(start_idx, len(nlp_df))):\n",
    "        row = nlp_df.iloc[i]\n",
    "        row_result = {\"industry\": row[\"industry\"], \"year\": row[\"year\"]}\n",
    "        for field in [\"summary\", \"trends\", \"infrastructure\", \"outlook\", \"timing_signal\"]:\n",
    "            sent = analyze_text(row.get(field, \"\"))\n",
    "            row_result.update({f\"{field}_{k}\": v for k, v in sent.items()})\n",
    "            if field in [\"summary\", \"outlook\", \"timing_signal\"]:\n",
    "                fin = finbert_score(row.get(field, \"\"), tokenizer, model)\n",
    "                row_result.update({f\"{field}_finbert_{k}\": v for k, v in fin.items()})\n",
    "        results.append(row_result)\n",
    "\n",
    "        # Checkpoint every N rows\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == len(nlp_df):\n",
    "            pd.DataFrame(results).to_csv(checkpoint_path, index=False)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_sentiment_df = score_nlp_df(nlp_df, checkpoint_path=outlook_checkpoint_path, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_sentiment_df.info()\n",
    "print(outlook_sentiment_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaing Up Null Values from LLM Classification (Mistral) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_rows_outlook = alignment_df[\n",
    "    (alignment_df['score'].isna()) |\n",
    "    (~alignment_df['raw_output'].str.strip().str.startswith(\"Answer:\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faulty_rows_outlook.shape)\n",
    "print(faulty_rows_outlook.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_rows_outlook_path = os.path.join(OUTPUT_NLP_FOLDER, \"faulty_rows_outlook.csv\")\n",
    "faulty_rows_outlook.to_csv(faulty_rows_outlook_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Founder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_rows_founder = nlp_founder_df[\n",
    "    (nlp_founder_df['score'].isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faulty_rows_founder.shape)\n",
    "print(faulty_rows_founder.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_rows_founder_path = os.path.join(OUTPUT_NLP_FOLDER, \"faulty_rows_founder.csv\")\n",
    "faulty_rows_founder.to_csv(faulty_rows_founder_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_scores_clean_path = os.path.join(OUTPUT_NLP_FOLDER, \"alignment_scores_clean.csv\")\n",
    "nlp_founder_clean_path = os.path.join(OUTPUT_NLP_FOLDER, \"founder_strength_scores_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_founder_new_score_path = os.path.join(OUTPUT_NLP_FOLDER, \"faulty_rows_founder_score.jsonl\")\n",
    "print(faulty_founder_new_score_path)\n",
    "\n",
    "faulty_outlook_new_score_path = os.path.join(OUTPUT_NLP_FOLDER, \"faulty_rows_outlook_alignment_v2.jsonl\")\n",
    "print(faulty_outlook_new_score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load reprocessed data ---\n",
    "faulty_founder_df = pd.read_json(faulty_founder_new_score_path, lines=True)\n",
    "faulty_outlook_df = pd.read_json(faulty_outlook_new_score_path, lines=True)\n",
    "\n",
    "# --- Fill missing scores with 2 ---\n",
    "faulty_founder_df[\"score\"] = faulty_founder_df[\"score\"].fillna(2)\n",
    "faulty_outlook_df[\"score\"] = faulty_outlook_df[\"score\"].fillna(2)\n",
    "\n",
    "# # --- Reload original full dataframes ---\n",
    "# alignment_df = pd.read_csv(\"your_path_to_alignment_df.csv\")     # <-- update path\n",
    "# nlp_founder_df = pd.read_csv(\"your_path_to_nlp_founder_df.csv\") # <-- update path\n",
    "\n",
    "# --- Clean & Recombine alignment_df ---\n",
    "alignment_df_clean = alignment_df[~alignment_df['org_uuid'].isin(faulty_outlook_df['org_uuid'])]\n",
    "alignment_df_final = pd.concat([alignment_df_clean, faulty_outlook_df], ignore_index=True)\n",
    "\n",
    "# --- Clean & Recombine nlp_founder_df ---\n",
    "nlp_founder_df_clean = nlp_founder_df[~nlp_founder_df['org_uuid'].isin(faulty_founder_df['org_uuid'])]\n",
    "nlp_founder_df_final = pd.concat([nlp_founder_df_clean, faulty_founder_df], ignore_index=True)\n",
    "\n",
    "# --- Sanity Checks ---\n",
    "print(\"Remaining null scores in alignment_df_final:\", alignment_df_final['score'].isna().sum())\n",
    "print(\"Bad raw_output format in alignment_df_final:\", (~alignment_df_final['raw_output'].astype(str).str.match(r\"^[1-5]$\")).sum())\n",
    "\n",
    "print(\"Remaining null scores in nlp_founder_df_final:\", nlp_founder_df_final['score'].isna().sum())\n",
    "print(\"Bad raw_output format in nlp_founder_df_final:\", (~nlp_founder_df_final['raw_output'].astype(str).str.match(r\"^[1-5]$\")).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_df_final.to_csv(nlp_scores_clean_path, index=False)\n",
    "nlp_founder_df_final.to_csv(nlp_founder_clean_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
