{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu-euoZ4HY8z"
      },
      "source": [
        "# Reinforcement Learning\n",
        "- Training 2 RL models: BASE vs FULL and comparing results\n",
        "- Simulates VC Portfolio allocation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpFsSsDKHkpS"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuB47us_H82Z"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGQF_lVylZoP",
        "outputId": "0c7fd79c-de58-45c0-8120-1df7ec24a336"
      },
      "outputs": [],
      "source": [
        "!pip install --no-cache-dir stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBWipRARHqQ1",
        "outputId": "e2f2262d-96f5-4ed1-aaab-646ca18f6064"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas numpy joblib scikit-learn gymnasium stable-baselines3 matplotlib seaborn scipy\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_0bnAWKnPez",
        "outputId": "f3b9b302-c7aa-4e3b-d587-85e9999637cc"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhsyAS9zPGkJ"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsaOaiKVO7cD",
        "outputId": "59cbd5b2-a9fa-4a2b-cf31-dc08b3e28cab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from scipy.stats import mannwhitneyu\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import seaborn as sns\n",
        "from joblib import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Ensure display options are set for pandas DataFrames\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "from google.colab import drive, runtime\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_yuq5z4PIUi"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4XUtKMIPBVn",
        "outputId": "5ff07c74-fd83-4d5b-e65c-03b65344bd44"
      },
      "outputs": [],
      "source": [
        "# === CONFIG ===\n",
        "INPUT_DIR = '/content/drive/MyDrive/Senior/Thesis/Code/Data/Input Data/model_data'\n",
        "MODEL_FOLDER = '/content/drive/MyDrive/Senior/Thesis/Code/Data/Output Data/Model'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Senior/Thesis/Code/Data/Output Data/RL_Model'\n",
        "DATA_PATH = os.path.join(INPUT_DIR, 'merged_startup_data.csv')\n",
        "\n",
        "CLASSIFIER_A_PATH = os.path.join(MODEL_FOLDER, 'best_model_success_label_5y_STATIC_MODEL_CatBoost_20250421-004244.pkl')\n",
        "CLASSIFIER_B_PATH = os.path.join(MODEL_FOLDER, 'best_model_success_label_5y_FULL_MODEL_CatBoost_20250421-004244.pkl')\n",
        "PREPROCESSOR_A_PATH = os.path.join(MODEL_FOLDER, 'preprocessor_success_label_5y_STATIC_MODEL_CatBoost_20250421-004244.pkl')\n",
        "PREPROCESSOR_B_PATH = os.path.join(MODEL_FOLDER, 'preprocessor_success_label_5y_FULL_MODEL_CatBoost_20250421-004244.pkl')\n",
        "SCALER_A_PATH = os.path.join(MODEL_FOLDER,'state_scaler_A.pkl')\n",
        "SCALER_B_PATH = os.path.join(MODEL_FOLDER, 'state_scaler_B.pkl')\n",
        "\n",
        "model_folder_contents = os.listdir(MODEL_FOLDER)\n",
        "print(model_folder_contents)\n",
        "\n",
        "known_industries = [\n",
        "   \"Life Sciences\", \"Fintech\", \"Consumer Goods\", \"Technology\",\n",
        "   \"Cleantech\", \"Transportation\", \"Media Entertainment and Gaming\",\n",
        "   \"Telecom\", \"Real Estate\"\n",
        "]\n",
        "\n",
        "# RL hyperparameters\n",
        "# 10 years\n",
        "SIM_TRAIN_START_YEAR = 2004\n",
        "SIM_TRAIN_END_YEAR = 2013\n",
        "# 3 years\n",
        "SIM_VALID_START_YEAR = 2014\n",
        "SIM_VALID_END_YEAR = 2016\n",
        "# 4 years\n",
        "SIM_TEST_START_YEAR = 2017\n",
        "SIM_TEST_END_YEAR = 2020\n",
        "\n",
        "# max number of investments is 20 over the time frame\n",
        "INITIAL_CAPITAL = 20_000_000\n",
        "INVESTMENT_UNIT = 1_000_000\n",
        "EPISODE_LENGTH_YEARS = 5\n",
        "\n",
        "REWARD_MAP = {\n",
        "    'ipo': +15,\n",
        "    'acquisition': +12,\n",
        "    # 'funded_no_exit': +1,\n",
        "    'closed': -20,\n",
        "    'still_active': 0,\n",
        "    'too_young': 0\n",
        "}\n",
        "\n",
        "RETURNS_MAP = {\n",
        "    'ipo': 10.0,\n",
        "    'acquisition': 8.0,\n",
        "    # 'funded_no_exit': 4.0,\n",
        "    'closed': 0.0,\n",
        "    'still_active': 0.0,\n",
        "    'too_young': 0.0\n",
        "}\n",
        "\n",
        "N_TRAIN_TIMESTEPS = 100000\n",
        "N_EVAL_EPISODES = 50\n",
        "DQN_GAMMA = 0.99\n",
        "DQN_LR = 1e-4\n",
        "DQN_BUFFER_SIZE = 50000\n",
        "DQN_BATCH_SIZE = 64\n",
        "DQN_EXPLORATION_FRACTION = 0.3\n",
        "DQN_EXPLORATION_FINAL_EPS = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF3pKvsg7l_Q"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jg4k60smL3K",
        "outputId": "9ac5b603-bb7a-4139-df86-4fa708f260cd"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(data_path, preprocessor_path, scaler_path, only_resolved=False, still_active_sample=0):\n",
        "    df = pd.read_csv(data_path)\n",
        "    df[\"industry_split\"] = df[\"industry\"].fillna(\"\").apply(lambda x: [s.strip() for s in x.split(\",\")])\n",
        "    mlb = MultiLabelBinarizer(classes=known_industries)\n",
        "    industry_df = pd.DataFrame(\n",
        "        mlb.fit_transform(df[\"industry_split\"]),\n",
        "        columns=[f\"industry_{c.replace(' ', '_').replace('_and_', '_')}\" for c in mlb.classes_]\n",
        "    )\n",
        "    industry_columns = industry_df.columns.tolist()\n",
        "    df = pd.concat([df.drop(columns=[\"industry\", \"industry_split\"]), industry_df], axis=1)\n",
        "\n",
        "    # --- Optional trimming for resolved outcomes only ---\n",
        "    if only_resolved:\n",
        "        initial_count = len(df)\n",
        "\n",
        "        # Step 1: Keep all startups with known outcomes\n",
        "        resolved_outcomes = ['ipo', 'acquisition','closed']\n",
        "        df_resolved = df[df['outcome_type'].isin(resolved_outcomes)].copy()\n",
        "\n",
        "        # Step 2: Sample still_active startups if requested\n",
        "        df_sampled = df_resolved\n",
        "        if still_active_sample > 0:\n",
        "            df_active_sample = df[df['outcome_type'] == 'still_active'].sample(n=still_active_sample, random_state=42)\n",
        "            df_young_sample = df[df['outcome_type'] == 'too_young'].sample(n=still_active_sample, random_state=42)\n",
        "            # df_funded_no_exit_sample = df[df['outcome_type'] == 'funded_no_exit'].sample(n=still_active_sample, random_state=42)\n",
        "            # df_sampled = pd.concat([df_resolved, df_funded_no_exit_sample, df_active_sample, df_young_sample])\n",
        "            df_sampled = pd.concat([df_resolved, df_active_sample, df_young_sample])\n",
        "            # df_sampled = pd.concat([df_resolved, df_active_sample])\n",
        "\n",
        "\n",
        "        df = df_sampled.sort_values(by=\"founded_year\").reset_index(drop=True)\n",
        "        print(f\"[INFO] Filtered to resolved outcomes + sampled still_active ({still_active_sample}): {len(df)} rows out of {initial_count}\")\n",
        "\n",
        "    else:\n",
        "        df = df.sort_values(by=\"founded_year\").reset_index(drop=True)\n",
        "\n",
        "    preprocessor = load(preprocessor_path)\n",
        "    state_scaler = joblib.load(scaler_path)\n",
        "\n",
        "    return df, preprocessor, state_scaler, industry_columns\n",
        "\n",
        "df_A, preprocessor_A, state_scaler_A, industry_columns = load_and_preprocess_data(DATA_PATH, PREPROCESSOR_A_PATH, SCALER_A_PATH, only_resolved=True, still_active_sample=4000)\n",
        "df_B, preprocessor_B, state_scaler_B, _ = load_and_preprocess_data(DATA_PATH, PREPROCESSOR_B_PATH, SCALER_B_PATH, only_resolved=True, still_active_sample=4000)\n",
        "\n",
        "# def load_and_preprocess_data(data_path, preprocessor_path):\n",
        "#     df = pd.read_csv(data_path)\n",
        "#     df[\"industry_split\"] = df[\"industry\"].fillna(\"\").apply(lambda x: [s.strip() for s in x.split(\",\")])\n",
        "#     mlb = MultiLabelBinarizer(classes=known_industries)\n",
        "#     industry_df = pd.DataFrame(\n",
        "#         mlb.fit_transform(df[\"industry_split\"]),\n",
        "#         columns=[f\"industry_{c.replace(' ', '_').replace('_and_', '_')}\" for c in mlb.classes_]\n",
        "#     )\n",
        "#     industry_columns = industry_df.columns.tolist()\n",
        "#     df = pd.concat([df.drop(columns=[\"industry\", \"industry_split\"]), industry_df], axis=1)\n",
        "\n",
        "#     df = df.sort_values(by='founded_year').reset_index(drop=True)\n",
        "#     preprocessor = load(preprocessor_path)\n",
        "\n",
        "#     return df, preprocessor, industry_columns\n",
        "\n",
        "# df_A, preprocessor_A, industry_columns = load_and_preprocess_data(DATA_PATH, PREPROCESSOR_A_PATH)\n",
        "# df_B, preprocessor_B, _ = load_and_preprocess_data(DATA_PATH, PREPROCESSOR_B_PATH)\n",
        "\n",
        "features_static = [\n",
        "    'founded_year', 'city', 'founder_count', 'founder_gender_diversity',\n",
        "    'has_top_school_founder', 'num_optimal_degrees', 'optimal_degree_ratio',\n",
        "    'is_repeat_founder', 'founder_gender_missing', 'founder_degree_missing',\n",
        "    'founder_school_missing', 'founder_desc_missing', 'has_funding_data',\n",
        "    'num_disclosed_rounds', 'has_disclosed_funding', 'first_funding_amount_bucket',\n",
        "    'is_startup_hub', 'cohort_funding_density', 'investor_count', 'has_known_investor'\n",
        "] + industry_columns\n",
        "\n",
        "features_macro = features_static + [\n",
        "    'age_at_first_funding', 'first_funding_delay', 'early_series_count',\n",
        "    'avg_time_to_early_round_months', 'avg_time_between_rounds', 'burn_rate',\n",
        "    'funding_velocity', 'gdp_growth_avg_15m', 'gdp_growth_delta_3m',\n",
        "    'interest_rate_fed_funds_avg_15m', 'interest_rate_fed_funds_delta_3m',\n",
        "    'fed_funds_rate_latest', 'yield_curve_10y_2y_avg_15m', 'yield_curve_inversion_flag',\n",
        "    'unemployment_rate_avg_15m', 'cpi_inflation_avg_15m', 'consumer_sentiment_avg_15m',\n",
        "    'consumer_sentiment_z_latest', 'vix_index_max_15m', 'vix_spike_flag', 'vix_latest',\n",
        "    'sp500_price_change_3m', 'sp500_volatility_3m', 'sp500_momentum_latest',\n",
        "    'avg_etf_return_3m', 'avg_etf_volatility_3m', 'avg_etf_momentum_latest',\n",
        "    'avg_etf_golden_cross_flag', 'avg_etf_ma50_to_price_ratio'\n",
        "]\n",
        "\n",
        "features_full = features_macro + [\n",
        "    'org_desc_sentiment_finbert', 'founder_desc_sentiment_finbert',\n",
        "    'org_desc_sim_exemplar', 'founder_desc_sim_exemplar', 'llm_founder_score',\n",
        "    'industry_outlook_sentiment_finbert', 'industry_timing_sentiment_finbert',\n",
        "    'llm_outlook_align_score_avg', 'llm_outlook_align_score_binned'\n",
        "]\n",
        "\n",
        "def load_classifier(path):\n",
        "    try:\n",
        "        print(f\"Loading classifier from {path}\")\n",
        "        return joblib.load(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load classifier: {e}\")\n",
        "        return None\n",
        "\n",
        "classifier_A = load_classifier(CLASSIFIER_A_PATH)\n",
        "classifier_B = load_classifier(CLASSIFIER_B_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ui4NYxrqLIf",
        "outputId": "72ef68d1-a8e9-448a-a848-397a57b0f77e"
      },
      "outputs": [],
      "source": [
        "print(df_A[\"outcome_type\"].value_counts())\n",
        "# print(df_A.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goM7lFR0Imor"
      },
      "source": [
        "## RL Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeO0k7OuPjLW"
      },
      "outputs": [],
      "source": [
        "class StartupInvestmentEnv(gymnasium.Env):\n",
        "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
        "\n",
        "    def __init__(self, df, classifier, feature_list, preprocessor, state_scaler, reward_map,\n",
        "                 sim_start_year, sim_end_year, initial_capital, investment_unit,\n",
        "                 episode_length_years=None, is_eval=False):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.classifier = classifier\n",
        "        # self.fixed_feature_list = feature_list_static\n",
        "        self.feature_list = feature_list # this one varies\n",
        "        self.preprocessor = preprocessor\n",
        "        self.state_scaler = state_scaler\n",
        "        self.reward_map = reward_map\n",
        "        self.sim_start_year = sim_start_year\n",
        "        self.sim_end_year = sim_end_year\n",
        "        self.initial_capital = initial_capital\n",
        "        self.investment_unit = investment_unit\n",
        "        self.episode_length_years = episode_length_years\n",
        "        self.is_eval = is_eval\n",
        "\n",
        "        self.max_investments_per_year = 5\n",
        "        self.context_features_dim = 3\n",
        "        self.state_dim = self._estimate_state_dim()\n",
        "\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_dim,), dtype=np.float32)\n",
        "\n",
        "        required_cols = feature_list + ['founded_year', 'outcome_type']\n",
        "        for col in required_cols:\n",
        "            if col not in self.df.columns:\n",
        "                raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "        self.sim_data = self.df[(self.df['founded_year'] >= self.sim_start_year) &\n",
        "                                (self.df['founded_year'] <= self.sim_end_year)].copy()\n",
        "        if self.sim_data.empty:\n",
        "            raise ValueError(\"No data found for specified simulation window.\")\n",
        "        self.sim_data.reset_index(drop=False, inplace=True)\n",
        "\n",
        "    def _estimate_state_dim(self):\n",
        "        dummy_row = self.df.iloc[0][self.feature_list]\n",
        "        transformed = self.preprocessor.transform(pd.DataFrame([dummy_row.to_dict()]))\n",
        "        return transformed.shape[1] + 1 + self.context_features_dim\n",
        "\n",
        "    def _get_state(self):\n",
        "        if self.candidate_idx_in_year >= len(self.current_year_candidates):\n",
        "            return np.zeros(self.state_dim, dtype=np.float32)\n",
        "\n",
        "        row = self.current_year_candidates.iloc[self.candidate_idx_in_year]\n",
        "        try:\n",
        "            row_data = row[self.feature_list].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "            candidate_df = pd.DataFrame([row_data.to_dict()])\n",
        "            transformed_features = self.preprocessor.transform(candidate_df).flatten()\n",
        "        except Exception as e:\n",
        "            print(f\"Preprocessor failed at idx {row['index']}: {e}\")\n",
        "            transformed_features = np.zeros(self.state_dim - 1 - self.context_features_dim)\n",
        "\n",
        "        try:\n",
        "            clf_input = transformed_features.reshape(1, -1)\n",
        "            prob_success = self.classifier.predict_proba(clf_input)[0, 1]\n",
        "        except Exception as e:\n",
        "            print(f\"Classifier failed at idx {row['index']}: {e}\")\n",
        "            prob_success = 0.0\n",
        "\n",
        "\n",
        "        # if I wanna fix the feature list for both (just static features), and then only use the full for the classifier on agent B\n",
        "        # idx = row['index']\n",
        "\n",
        "        # # === 1. Use fixed (static) features for the RL state ===\n",
        "        # try:\n",
        "        #     row_data_state = row[self.rl_feature_list]  # <- static features only\n",
        "        #     X_state = pd.DataFrame([row_data_state.to_dict()])\n",
        "        #     transformed_features = self.preprocessor.transform(X_state).flatten()\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Preprocessor failed on state features at idx {idx}: {e}\")\n",
        "        #     transformed_features = np.zeros(self.state_dim - 1 - self.context_features_dim)\n",
        "\n",
        "        # # === 2. Use model-specific features for classifier.predict_proba() ===\n",
        "        # try:\n",
        "        #     row_data_clf = row[self.feature_list]  # <- full or static, depending on classifier\n",
        "        #     X_clf = pd.DataFrame([row_data_clf.to_dict()])\n",
        "        #     clf_input = self.preprocessor.transform(X_clf)\n",
        "        #     prob_success = self.classifier.predict_proba(clf_input)[0, 1]\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Classifier failed on input features at idx {idx}: {e}\")\n",
        "        #     prob_success = 0.0\n",
        "\n",
        "        capital_ratio = self.available_capital / self.initial_capital\n",
        "        year_progress = (self.current_sim_year - self.start_year_episode) / max(1, self.sim_end_year - self.start_year_episode)\n",
        "        portfolio_ratio = len(self.portfolio) / max(1, (self.initial_capital // self.investment_unit))\n",
        "\n",
        "        context_features = np.array([capital_ratio, year_progress, portfolio_ratio], dtype=np.float32)\n",
        "        raw_state = np.concatenate([transformed_features, [prob_success], context_features])\n",
        "        state = self.state_scaler.transform(raw_state.reshape(1, -1)).flatten()\n",
        "\n",
        "        return state.astype(np.float32)\n",
        "\n",
        "    def _calculate_reward(self, idx):\n",
        "        outcome_type = self.df.loc[idx, 'outcome_type']\n",
        "        return self.reward_map.get(outcome_type, 0)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_sim_year = self.sim_start_year\n",
        "        self.start_year_episode = self.sim_start_year\n",
        "        self.available_capital = self.initial_capital\n",
        "        self.portfolio = {}\n",
        "        self.investment_log = []\n",
        "        self.investments_this_year = 0\n",
        "\n",
        "        # Refresh and shuffle candidates for this year\n",
        "        self._refresh_candidates_for_year()\n",
        "        return self._get_state(), {}\n",
        "\n",
        "    def _refresh_candidates_for_year(self):\n",
        "        self.current_year_candidates = (\n",
        "            self.sim_data[self.sim_data['founded_year'] == self.current_sim_year]\n",
        "            .sample(frac=1, random_state=np.random.randint(0, 1e6))  # shuffle candidates\n",
        "            .reset_index(drop=False)\n",
        "        )\n",
        "        self.candidate_idx_in_year = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        reward = 0\n",
        "\n",
        "        if self.candidate_idx_in_year >= len(self.current_year_candidates) or self.investments_this_year >= self.max_investments_per_year:\n",
        "            self.current_sim_year += 1\n",
        "            if self.current_sim_year > self.sim_end_year:\n",
        "                return np.zeros(self.state_dim, dtype=np.float32), 0, True, False, {}\n",
        "\n",
        "            self.investments_this_year = 0\n",
        "            self._refresh_candidates_for_year()\n",
        "\n",
        "        if self.candidate_idx_in_year >= len(self.current_year_candidates):\n",
        "            return self.step(action=0)  # skip if no startups\n",
        "\n",
        "        row = self.current_year_candidates.iloc[self.candidate_idx_in_year]\n",
        "        idx = row['index']\n",
        "        self.candidate_idx_in_year += 1\n",
        "\n",
        "        invested = False\n",
        "        if action == 1 and self.available_capital >= self.investment_unit and self.investments_this_year < self.max_investments_per_year:\n",
        "            self.available_capital -= self.investment_unit\n",
        "            reward = self._calculate_reward(idx)\n",
        "            self.portfolio[idx] = {\n",
        "                'invest_year': self.current_sim_year,\n",
        "                'status': 'active',\n",
        "                'reward': reward,\n",
        "                'outcome_type': row['outcome_type']\n",
        "            }\n",
        "            invested = True\n",
        "            self.investments_this_year += 1\n",
        "\n",
        "        self.investment_log.append({\n",
        "            'year': self.current_sim_year,\n",
        "            'startup_idx': idx,\n",
        "            'decision': 'invest' if invested else 'pass'\n",
        "        })\n",
        "\n",
        "        if not self.is_eval and self.episode_length_years is not None:\n",
        "            if (self.current_sim_year - self.start_year_episode) >= self.episode_length_years:\n",
        "                truncated = True\n",
        "\n",
        "        next_state = np.zeros(self.state_dim, dtype=np.float32) if truncated else self._get_state()\n",
        "\n",
        "        info = {\n",
        "            'capital': self.available_capital,\n",
        "            'portfolio_size': len(self.portfolio),\n",
        "            'current_year': self.current_sim_year,\n",
        "            'invested_this_step': invested,\n",
        "            'startup_idx': idx,\n",
        "            'true_outcome': row['outcome_type']\n",
        "        }\n",
        "\n",
        "        return next_state, reward, False, truncated, info\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        if mode == \"human\":\n",
        "            print(f\"Year: {self.current_sim_year}, Capital: {self.available_capital:.0f}, Portfolio: {len(self.portfolio)}\")\n",
        "        else:\n",
        "            super().render(mode=mode)\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK4vLTdh-jtn"
      },
      "source": [
        "## Training & Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOgkI8rCPnsP"
      },
      "outputs": [],
      "source": [
        "def train_agent(env_id, agent_name, df, classifier, feature_list, preprocessor, state_scaler, reward_map,\n",
        "                train_start, train_end, valid_start, valid_end, episode_length):\n",
        "    print(f\"\\n--- Training Agent: {agent_name} ---\")\n",
        "    model_save_path = os.path.join(OUTPUT_DIR, f'{agent_name}_dqn')\n",
        "    log_dir = os.path.join(OUTPUT_DIR, f'{agent_name}_logs')\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    train_env = StartupInvestmentEnv(df, classifier, feature_list, preprocessor, state_scaler, reward_map,\n",
        "                                     train_start, train_end, INITIAL_CAPITAL, INVESTMENT_UNIT,\n",
        "                                     episode_length_years=episode_length, is_eval=False)\n",
        "    train_env = Monitor(train_env, log_dir)\n",
        "\n",
        "    eval_env = StartupInvestmentEnv(df, classifier, feature_list, preprocessor, state_scaler, reward_map,\n",
        "                                    valid_start, valid_end, INITIAL_CAPITAL, INVESTMENT_UNIT,\n",
        "                                    is_eval=True)\n",
        "    eval_env = Monitor(eval_env, os.path.join(log_dir, 'eval'))\n",
        "\n",
        "    eval_callback = EvalCallback(eval_env,\n",
        "                                 best_model_save_path=os.path.join(OUTPUT_DIR, f'{agent_name}_best'),\n",
        "                                 log_path=os.path.join(log_dir, 'eval_results'),\n",
        "                                 eval_freq=max(N_TRAIN_TIMESTEPS // 20, 500),\n",
        "                                 n_eval_episodes=5,\n",
        "                                 deterministic=True,\n",
        "                                 render=False)\n",
        "\n",
        "    model = DQN(\"MlpPolicy\", train_env,\n",
        "                gamma=DQN_GAMMA,\n",
        "                learning_rate=DQN_LR,\n",
        "                buffer_size=DQN_BUFFER_SIZE,\n",
        "                batch_size=DQN_BATCH_SIZE,\n",
        "                exploration_fraction=DQN_EXPLORATION_FRACTION,\n",
        "                exploration_final_eps=DQN_EXPLORATION_FINAL_EPS,\n",
        "                verbose=1,\n",
        "                tensorboard_log=log_dir)\n",
        "\n",
        "    model.learn(total_timesteps=N_TRAIN_TIMESTEPS, callback=eval_callback, log_interval=100)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Final model saved to {model_save_path}\")\n",
        "    print(f\"Best model saved to {os.path.join(OUTPUT_DIR, f'{agent_name}_best')}\")\n",
        "\n",
        "    return os.path.join(OUTPUT_DIR, f'{agent_name}_best', 'best_model.zip')\n",
        "\n",
        "def evaluate_agent(model_path, agent_name, df, classifier, feature_list, preprocessor, state_scaler,\n",
        "                   reward_map, returns_map, test_start, test_end):\n",
        "    print(f\"\\n--- Evaluating Agent: {agent_name} on Test Set ---\")\n",
        "    model = DQN.load(model_path)\n",
        "\n",
        "    test_env = StartupInvestmentEnv(\n",
        "        df, classifier, feature_list, preprocessor, state_scaler, reward_map,\n",
        "        test_start, test_end, INITIAL_CAPITAL, INVESTMENT_UNIT, is_eval=True\n",
        "    )\n",
        "\n",
        "    EVAL_YEARS = test_end - test_start + 1\n",
        "    results = []\n",
        "    all_episode_investments = {} # tracking the startups invested in\n",
        "\n",
        "    for ep in range(N_EVAL_EPISODES):\n",
        "        obs, _ = test_env.reset()\n",
        "        terminated = truncated = False\n",
        "        capital_invested = 0\n",
        "        reward_total = 0\n",
        "        total_return = 0\n",
        "\n",
        "        while not terminated and not truncated:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = test_env.step(action)\n",
        "            reward_total += reward\n",
        "            if info.get(\"invested_this_step\", False):\n",
        "                capital_invested += INVESTMENT_UNIT\n",
        "\n",
        "        # Outcome-based returns\n",
        "        outcome_counts = {k: 0 for k in returns_map}\n",
        "        for inv_info in test_env.portfolio.values():\n",
        "            outcome = inv_info['outcome_type']\n",
        "            multiplier = returns_map.get(outcome, 1.0)  # fallback to 1.0 if unknown\n",
        "            total_return += multiplier * INVESTMENT_UNIT\n",
        "\n",
        "            if outcome in outcome_counts:\n",
        "                outcome_counts[outcome] += 1\n",
        "            else:\n",
        "                print(f\"Warning: Unexpected outcome '{outcome}'\")\n",
        "\n",
        "        # Metrics\n",
        "        moic = total_return / max(capital_invested, 1)\n",
        "        roi = (total_return - capital_invested) / max(capital_invested, 1)\n",
        "        approx_irr = (moic ** (1 / EVAL_YEARS)) - 1 if capital_invested > 0 else 0\n",
        "\n",
        "        investment_rate = len(test_env.portfolio) / max(1, len(test_env.investment_log))\n",
        "\n",
        "        # track investments\n",
        "        invested_indices = list(test_env.portfolio.keys())\n",
        "        all_episode_investments[ep + 1] = invested_indices\n",
        "\n",
        "        results.append({\n",
        "            \"Episode\": ep + 1,\n",
        "            \"Investments\": len(test_env.portfolio),\n",
        "            \"Investment Rate\": investment_rate,\n",
        "            \"Capital Invested\": capital_invested,\n",
        "            \"Total Return\": total_return,\n",
        "            \"MOIC\": moic,\n",
        "            \"ROI\": roi,\n",
        "            \"Approx IRR\": approx_irr,\n",
        "            \"Reward Score (non-financial)\": reward_total,\n",
        "            **outcome_counts\n",
        "        })\n",
        "\n",
        "        print(f\"Episode {ep+1}: MOIC = {moic:.2f}, ROI = {roi:.2%}, IRR ≈ {approx_irr:.2%}, Total Return = ${total_return:,.0f}\")\n",
        "\n",
        "    return pd.DataFrame(results), all_episode_investments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlkRaCTmnZ0n"
      },
      "outputs": [],
      "source": [
        "def extract_best_episode_portfolio(eval_df, df, all_episode_investments, metric=\"Total Return\", agent_name=\"Agent\"):\n",
        "    \"\"\"\n",
        "    Extracts the startup rows from the best-performing evaluation episode.\n",
        "\n",
        "    Args:\n",
        "        eval_df (pd.DataFrame): Output of evaluate_agent().\n",
        "        all_episode_investments (dict): Mapping from episode number → list of invested startup indices.\n",
        "        metric (str): Column to use for selecting best episode (e.g. 'Total Return').\n",
        "        agent_name (str): Used for file naming and labeling.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame of startup rows for the best episode.\n",
        "    \"\"\"\n",
        "    best_ep = eval_df.sort_values(by=metric, ascending=False).iloc[0][\"Episode\"]\n",
        "    best_indices = all_episode_investments.get(best_ep, [])\n",
        "\n",
        "    if not best_indices:\n",
        "        print(f\"[Warning] No investments found for best episode {best_ep} of {agent_name}.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    portfolio_df = df.loc[best_indices].copy()\n",
        "    portfolio_df[\"Episode\"] = best_ep\n",
        "    portfolio_df[\"Agent\"] = agent_name\n",
        "\n",
        "    # Optional: save to CSV\n",
        "    filename = f\"best_episode_portfolio_{agent_name.replace(' ', '_')}.csv\"\n",
        "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "    portfolio_df.to_csv(filepath, index=False)\n",
        "    print(f\"[Saved] Best episode portfolio for {agent_name} → {filepath}\")\n",
        "\n",
        "    return portfolio_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZkWHMGF-ooO"
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAaHbPXJeX-F"
      },
      "source": [
        "### Agent A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pK8dZV8PQMp"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6gS0hDpmPxnO",
        "outputId": "7b2bcbc1-15c3-48e6-e8ea-b2635455c2fb"
      },
      "outputs": [],
      "source": [
        "# === Run Full Training + Evaluation Pipeline ===\n",
        "if classifier_A:\n",
        "  best_model_A_path = train_agent('Agent_A_Static', 'Agent_A_Static', df_A, classifier_A, features_static,\n",
        "                                  preprocessor_A, state_scaler_A, REWARD_MAP, SIM_TRAIN_START_YEAR, SIM_TRAIN_END_YEAR,\n",
        "                                  SIM_VALID_START_YEAR, SIM_VALID_END_YEAR, EPISODE_LENGTH_YEARS)\n",
        "\n",
        "  df_eval_A, investments_A = evaluate_agent(best_model_A_path, 'Agent_A_Static', df_A, classifier_A, features_static,\n",
        "                              preprocessor_A, state_scaler_A, REWARD_MAP, RETURNS_MAP, SIM_TEST_START_YEAR, SIM_TEST_END_YEAR)\n",
        "\n",
        "  df_best_A = extract_best_episode_portfolio(df_eval_A, df_A, investments_A, metric=\"Total Return\", agent_name=\"Agent A\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ORE5vuBUAfm"
      },
      "outputs": [],
      "source": [
        "df_eval_A.to_csv(os.path.join(OUTPUT_DIR, 'STATIC_RL_evaluation.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ncnEtFlPSef"
      },
      "source": [
        "#### Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CW39PJt5MKeh",
        "outputId": "26b3f1f5-7a9d-49ab-dfb3-8065458ce31f"
      },
      "outputs": [],
      "source": [
        "# print(df_eval_A.info())\n",
        "print(df_eval_A.head(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oaQBXIcFoJeX",
        "outputId": "092bb4b0-1295-4d8f-e762-12ce47576c37"
      },
      "outputs": [],
      "source": [
        "# print(df_best_A.info())\n",
        "print(df_best_A.head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP5SitwkeZqA"
      },
      "source": [
        "### Agent B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGr5B062S3bi"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqPpCd4zL25I",
        "outputId": "f0b79989-9811-4fa3-9345-614d0447247a"
      },
      "outputs": [],
      "source": [
        "if classifier_B:\n",
        "  # === Run Full Training + Evaluation Pipeline ===\n",
        "  best_model_B_path = train_agent('Agent_B_Full', 'Agent_B_Full', df_B, classifier_B, features_full,\n",
        "                                  preprocessor_B, state_scaler_B, REWARD_MAP, SIM_TRAIN_START_YEAR, SIM_TRAIN_END_YEAR,\n",
        "                                  SIM_VALID_START_YEAR, SIM_VALID_END_YEAR, EPISODE_LENGTH_YEARS)\n",
        "\n",
        "  df_eval_B, investments_B = evaluate_agent(best_model_B_path, 'Agent_B_Full', df_B, classifier_B, features_full,\n",
        "                              preprocessor_B, state_scaler_B, REWARD_MAP, RETURNS_MAP, SIM_TEST_START_YEAR, SIM_TEST_END_YEAR)\n",
        "\n",
        "  df_best_B = extract_best_episode_portfolio(df_eval_B, df_B, investments_B, metric=\"Total Return\", agent_name=\"Agent B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mop80wAtUKBv"
      },
      "outputs": [],
      "source": [
        "df_eval_B.to_csv(os.path.join(OUTPUT_DIR, 'FULL_RL_evaluation.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVY8uEdKSsuQ"
      },
      "source": [
        "#### Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "WMtWrSdTULGZ",
        "outputId": "edd3aa19-95bb-47fe-a073-a6a3ad6a7061"
      },
      "outputs": [],
      "source": [
        "# print(df_eval_B.info())\n",
        "print(df_eval_B.head(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dQAfeLaoBsT"
      },
      "outputs": [],
      "source": [
        "# print(df_best_B.info())\n",
        "print(df_best_B.head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKRca-DWf47l"
      },
      "source": [
        "## Compare and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc_C8J2Rk3Lg"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euK1QQIEfmlj"
      },
      "outputs": [],
      "source": [
        "def compare_portfolio_returns(df_A, df_B, agent_name_A=\"Agent A\", agent_name_B=\"Agent B\"):\n",
        "    \"\"\"\n",
        "    Compares total returns between two agents.\n",
        "    Args:\n",
        "        df_A (pd.DataFrame): Evaluation results from agent A (must include 'Total Return')\n",
        "        df_B (pd.DataFrame): Evaluation results from agent B (must include 'Total Return')\n",
        "    \"\"\"\n",
        "\n",
        "    ret_A = df_A[\"Total Return\"]\n",
        "    ret_B = df_B[\"Total Return\"]\n",
        "\n",
        "    irr_A = df_A[\"Approx IRR\"]\n",
        "    irr_B = df_B[\"Approx IRR\"]\n",
        "\n",
        "    reward_A = df_A[\"Reward Score (non-financial)\"]\n",
        "    reward_B = df_B[\"Reward Score (non-financial)\"]\n",
        "\n",
        "    moic_A = df_A[\"MOIC\"]\n",
        "    moic_B = df_B[\"MOIC\"]\n",
        "\n",
        "    # print(\"\\n--- Total Return Comparison ---\")\n",
        "    # print(f\"{agent_name_A}: Mean = ${np.mean(ret_A):,.0f}, Std = ${np.std(ret_A):,.0f}\")\n",
        "    # print(f\"{agent_name_B}: Mean = ${np.mean(ret_B):,.0f}, Std = ${np.std(ret_B):,.0f}\")\n",
        "\n",
        "    # u_stat, p_val = mannwhitneyu(ret_A, ret_B, alternative='less')\n",
        "    # print(f\"Mann-Whitney U test ({agent_name_A} < {agent_name_B}): U = {u_stat:.2f}, p = {p_val:.4f}\")\n",
        "    # if p_val < 0.05:\n",
        "    #     print(f\"→ Statistically significant: {agent_name_B} outperforms {agent_name_A}.\")\n",
        "    # else:\n",
        "    #     print(\"→ No significant difference detected.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n--- Total Return + Financial Metrics Comparison ---\")\n",
        "\n",
        "    for agent_df, agent_name in [(df_A, agent_name_A), (df_B, agent_name_B)]:\n",
        "        total_return_mean = agent_df[\"Total Return\"].mean()\n",
        "        total_return_std = agent_df[\"Total Return\"].std()\n",
        "        roi_mean = agent_df[\"ROI\"].mean()\n",
        "        total_reward_mean = agent_df[\"Reward Score (non-financial)\"].mean()\n",
        "        moic_mean = agent_df[\"MOIC\"].mean()\n",
        "        irr_mean = agent_df[\"Approx IRR\"].mean()\n",
        "\n",
        "        # Outcome columns (based on known outcome types)\n",
        "        outcome_cols = [col for col in agent_df.columns if col.lower() in ['ipo', 'acquisition', 'closed', 'still_active', 'too_young']]\n",
        "        outcome_means = agent_df[outcome_cols].mean().to_dict()\n",
        "\n",
        "        # Store for CSV\n",
        "        summary_row = {\n",
        "            \"Agent\": agent_name,\n",
        "            \"Mean Total Return\": total_return_mean,\n",
        "            \"Std Total Return\": total_return_std,\n",
        "            \"Mean Reward Score\": total_reward_mean,\n",
        "            \"Mean ROI\": roi_mean,\n",
        "            \"Mean MOIC\": moic_mean,\n",
        "            \"Mean IRR\": irr_mean,\n",
        "            **{f\"Avg {k.title()}\": v for k, v in outcome_means.items()}\n",
        "        }\n",
        "        results.append(summary_row)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n{agent_name}\")\n",
        "        print(f\"- Mean Total Return: ${total_return_mean:,.0f} (±{total_return_std:,.0f})\")\n",
        "        print(f\"- Mean Total Reward Score: {total_reward_mean:.2f}\")\n",
        "        print(f\"- Mean ROI: {roi_mean:.2%}\")\n",
        "        print(f\"- Mean MOIC: {moic_mean:.3f}\")\n",
        "        print(f\"- Mean IRR: {irr_mean:.2%}\")\n",
        "        print(\"\\nAverage Outcome Counts per Episode:\")\n",
        "        for outcome, avg_count in sorted(outcome_means.items(), key=lambda x: -x[1]):\n",
        "            print(f\"  - {outcome}: {avg_count:.2f}\")\n",
        "\n",
        "    # Run statistical test\n",
        "    u_stat, p_val = mannwhitneyu(df_A[\"Total Return\"], df_B[\"Total Return\"], alternative='less')\n",
        "    print(f\"\\nMann-Whitney U test ({agent_name_A} < {agent_name_B}): U = {u_stat:.2f}, p = {p_val:.4f}\")\n",
        "    if p_val < 0.05:\n",
        "        print(f\"→ Statistically significant: {agent_name_B} outperforms {agent_name_A}.\")\n",
        "    else:\n",
        "        print(\"→ No significant difference detected.\")\n",
        "\n",
        "\n",
        "    results.append({\n",
        "        \"Agent\": \"Statistical Test\",\n",
        "        \"Mann-Whitney U Test\": f\"\\nMann-Whitney U test ({agent_name_A} < {agent_name_B}): U = {u_stat:.2f}, p = {p_val:.4f}\",\n",
        "        \"Significance\": f\"Statistically significant: {agent_name_B} outperforms {agent_name_A}.\" if p_val < 0.05 else \"→ No significant difference detected.\",\n",
        "        \"Std Total Return\": p_val\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    csv_path = os.path.join(OUTPUT_DIR, \"agent_comparison_summary.csv\")\n",
        "    results_df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\n[Saved] Comparison summary CSV → {csv_path}\")\n",
        "\n",
        "    # --- Plotting Function ---\n",
        "    def plot_metric(dist_A, dist_B, title, xlabel, filename, is_percentage=False):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        sns.histplot(dist_A, kde=True, color='skyblue', label=f'{agent_name_A}\\nMean={np.mean(dist_A):.2%}' if is_percentage else f'{agent_name_A}\\nMean={np.mean(dist_A):,.2f}')\n",
        "        sns.histplot(dist_B, kde=True, color='lightcoral', label=f'{agent_name_B}\\nMean={np.mean(dist_B):.2%}' if is_percentage else f'{agent_name_B}\\nMean={np.mean(dist_B):,.2f}')\n",
        "        plt.title(title)\n",
        "        plt.xlabel(xlabel)\n",
        "        plt.ylabel('Frequency')\n",
        "        if is_percentage:\n",
        "            plt.gca().xaxis.set_major_formatter(PercentFormatter(1.0))\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"{title} plot saved to {save_path}\")\n",
        "        plt.show()\n",
        "\n",
        "    # --- Generate all four plots ---\n",
        "    plot_metric(ret_A, ret_B, \"Distribution of Total Returns\", \"Total Return ($)\", \"return_comparison.png\", is_percentage=False)\n",
        "    plot_metric(irr_A, irr_B, \"Distribution of Approximate IRRs\", \"Approximate IRR\", \"irr_comparison.png\", is_percentage=True)\n",
        "    plot_metric(reward_A, reward_B, \"Distribution of Reward Scores\", \"Reward Score (Non-Financial)\", \"reward_score_comparison.png\", is_percentage=False)\n",
        "    plot_metric(moic_A, moic_B, \"Distribution of MOIC\", \"MOIC\", \"moic_comparison.png\", is_percentage=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4gEfMp5ci5g"
      },
      "outputs": [],
      "source": [
        "def analyze_evaluation_results(eval_df, agent_name):\n",
        "    \"\"\"\n",
        "    Visualizes performance metrics: reward, MOIC, ROI, IRR, and outcome distribution.\n",
        "    Args:\n",
        "        eval_df (pd.DataFrame): Output of evaluate_agent().\n",
        "        agent_name (str): Name of the agent to use in titles/labels.\n",
        "    \"\"\"\n",
        "    if eval_df is None or eval_df.empty:\n",
        "        print(\"Evaluation DataFrame is empty. Skipping analysis.\")\n",
        "        return\n",
        "\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # print(f\"\\n=== {agent_name} Evaluation Summary ===\")\n",
        "    # print(f\"Avg MOIC: {eval_df['MOIC'].mean():.3f}\")\n",
        "    # print(f\"Avg ROI: {eval_df['ROI'].mean():.2%}\")\n",
        "    # print(f\"Avg IRR: {eval_df['Approx IRR'].mean():.2%}\")\n",
        "    # print(f\"Avg Investments per Episode: {eval_df['Investments'].mean():.1f}\")\n",
        "\n",
        "    # --- Print total outcome counts ---\n",
        "    outcome_cols = [col for col in eval_df.columns if col not in [\n",
        "        \"Episode\", \"Investments\", \"Investment Rate\", \"Capital Invested\", \"Total Return\",\n",
        "        \"MOIC\", \"ROI\", \"Approx IRR\", \"Reward Score (non-financial)\"\n",
        "    ]]\n",
        "    outcome_totals = eval_df[outcome_cols].sum().sort_values(ascending=False)\n",
        "    print(\"\\nOutcome Type Distribution Across All Episodes:\")\n",
        "    print(outcome_totals)\n",
        "\n",
        "    # --- Plot Total Return ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.lineplot(data=eval_df, x=\"Episode\", y=\"Total Return\", marker=\"o\")\n",
        "    plt.title(f\"{agent_name} – Total Return per Evaluation Episode\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Return ($)\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot MOIC per episode ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.lineplot(data=eval_df, x=\"Episode\", y=\"MOIC\", marker=\"o\")\n",
        "    plt.title(f\"{agent_name} – MOIC per Evaluation Episode\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"MOIC\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot ROI per episode ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.lineplot(data=eval_df, x=\"Episode\", y=\"ROI\", marker=\"o\")\n",
        "    plt.title(f\"{agent_name} – ROI per Evaluation Episode\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"ROI\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot IRR per episode ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.lineplot(data=eval_df, x=\"Episode\", y=\"Approx IRR\", marker=\"o\")\n",
        "    plt.title(f\"{agent_name} – IRR per Evaluation Episode (approx.)\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"IRR\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot Outcome Distribution ---\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.barplot(x=outcome_totals.index, y=outcome_totals.values)\n",
        "    plt.title(f\"{agent_name} – Total Outcome Counts Across Evaluation\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZSMYTMk44P"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPWhBNSyefEG"
      },
      "outputs": [],
      "source": [
        "df_eval_A = pd.read_csv(os.path.join(OUTPUT_DIR, 'STATIC_RL_evaluation.csv'))\n",
        "df_eval_B = pd.read_csv(os.path.join(OUTPUT_DIR, 'FULL_RL_evaluation.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f4aUiNw7Ts5V",
        "outputId": "25909887-4b77-4858-a140-aa7642091104"
      },
      "outputs": [],
      "source": [
        "compare_portfolio_returns(df_eval_A, df_eval_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y0DeXyt5TzKx",
        "outputId": "f6882631-ba59-43ee-c71d-ff6a23800d5f"
      },
      "outputs": [],
      "source": [
        "analyze_evaluation_results(df_eval_A, 'Agent_A_Static')\n",
        "analyze_evaluation_results(df_eval_B, 'Agent_B_Full')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fzXTU_leM72"
      },
      "source": [
        "## (Run Once) Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YXd7Vi-ePjS",
        "outputId": "569f957a-ef20-42d4-ec36-ffef162ba0bc"
      },
      "outputs": [],
      "source": [
        "# === CONFIG ===\n",
        "TRAIN_YEARS = (2010, 2018) # RL Training Period\n",
        "SCALER_STATIC_PATH = os.path.join(MODEL_FOLDER,'state_scaler_A.pkl') # Keep A/B naming convention\n",
        "SCALER_FULL_PATH = os.path.join(MODEL_FOLDER, 'state_scaler_B.pkl') # Keep A/B naming convention\n",
        "\n",
        "# Maximum number of samples to use for fitting scaler (to avoid memory issues if data is huge)\n",
        "MAX_SAMPLES_FOR_SCALER = 50000\n",
        "\n",
        "# === Helper function (Corrected) ===\n",
        "def fit_and_save_state_scaler(df, feature_list, preprocessor, classifier, scaler_save_path, label):\n",
        "    print(f\"\\n--- Fitting state scaler for {label} model ---\")\n",
        "    print(f\"Filtering data to years {TRAIN_YEARS[0]}-{TRAIN_YEARS[1]}...\")\n",
        "    df_train = df[(df['founded_year'] >= TRAIN_YEARS[0]) & (df['founded_year'] <= TRAIN_YEARS[1])].copy()\n",
        "\n",
        "    if df_train.empty:\n",
        "        print(f\"No training data found for years {TRAIN_YEARS}. Cannot fit scaler for {label}.\")\n",
        "        return\n",
        "\n",
        "    # Sample if the dataset slice is very large\n",
        "    if len(df_train) > MAX_SAMPLES_FOR_SCALER:\n",
        "        print(f\"Sampling {MAX_SAMPLES_FOR_SCALER} from {len(df_train)} rows for scaler fitting.\")\n",
        "        df_train = df_train.sample(n=MAX_SAMPLES_FOR_SCALER, random_state=42)\n",
        "\n",
        "    # Check if feature list is empty or None\n",
        "    if not feature_list:\n",
        "         print(f\"Error: Feature list for {label} is empty or None. Skipping.\")\n",
        "         return\n",
        "\n",
        "    # Ensure all features are in the dataframe before selection\n",
        "    missing_features = [f for f in feature_list if f not in df_train.columns]\n",
        "    if missing_features:\n",
        "         print(f\"Error: Missing features in dataframe for {label}: {missing_features}. Skipping.\")\n",
        "         return\n",
        "\n",
        "    X_raw = df_train[feature_list]\n",
        "    X_raw.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    print(f\"Preprocessing {len(X_raw)} samples...\")\n",
        "    try:\n",
        "        X_transformed = preprocessor.transform(X_raw)\n",
        "        # Handle sparse matrix output if necessary\n",
        "        if hasattr(X_transformed, \"toarray\"):\n",
        "            X_transformed = X_transformed.toarray()\n",
        "    except Exception as e:\n",
        "         print(f\"Error during preprocessing transform for {label}: {e}. Skipping.\")\n",
        "         return\n",
        "\n",
        "    print(f\"Getting classifier probabilities for {label}...\")\n",
        "    print(\"Classifier expected:\", classifier.n_features_in_)\n",
        "    print(\"Transformed features:\", X_transformed.shape[1])\n",
        "\n",
        "    try:\n",
        "        # if hasattr(classifier, \"predict_proba\"):\n",
        "        #     # Ensure X_transformed has the correct number of features expected by classifier\n",
        "        #     if hasattr(classifier, 'n_features_in_') and classifier.n_features_in_ != X_transformed.shape[1]:\n",
        "        #          raise ValueError(f\"Feature mismatch for classifier. Expected {classifier.n_features_in_}, got {X_transformed.shape[1]}\")\n",
        "\n",
        "            probs = classifier.predict_proba(X_transformed)[:, 1].reshape(-1, 1)\n",
        "        # else:\n",
        "        #     raise ValueError(f\"{label} classifier does not support predict_proba\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting probabilities for {label}: {e}. Skipping.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    print(f\"Generating sampled context features...\")\n",
        "    n_samples = X_transformed.shape[0]\n",
        "    # --- Generate VARYING Context Features ---\n",
        "    np.random.seed(42)\n",
        "    context = np.hstack([\n",
        "        np.random.uniform(0.1, 1.0, size=(n_samples, 1)), # capital_ratio varies\n",
        "        np.random.uniform(0.0, 1.0, size=(n_samples, 1)), # year_progress varies\n",
        "        np.random.uniform(0.0, 0.8, size=(n_samples, 1))  # portfolio_ratio varies\n",
        "    ])\n",
        "    # --- End Corrected Context ---\n",
        "\n",
        "    print(f\"Concatenating state matrix...\")\n",
        "    try:\n",
        "        state_matrix = np.hstack([X_transformed, probs, context])\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during hstack (check shapes): {e}\")\n",
        "        print(f\"X_transformed shape: {X_transformed.shape}\")\n",
        "        print(f\"probs shape: {probs.shape}\")\n",
        "        print(f\"context shape: {context.shape}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Fitting StandardScaler on state matrix with shape {state_matrix.shape}...\")\n",
        "    try:\n",
        "        state_scaler = StandardScaler().fit(state_matrix)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fitting StandardScaler for {label}: {e}. Skipping.\")\n",
        "        # Check for issues like all-zero columns if error occurs\n",
        "        # print(\"Checking for constant columns (std dev = 0):\")\n",
        "        # print(np.std(state_matrix, axis=0))\n",
        "        return\n",
        "\n",
        "    print(f\"Saving scaler for {label}...\")\n",
        "\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(scaler_save_path), exist_ok=True) # Ensure directory exists\n",
        "        joblib.dump(state_scaler, scaler_save_path)\n",
        "        print(f\"{label} state scaler saved to: {scaler_save_path}\")\n",
        "        print(f\"Scaler expects input shape: ({state_scaler.n_features_in_},)\") # Info\n",
        "    except Exception as e:\n",
        "         print(f\"Error saving scaler for {label} to {scaler_save_path}: {e}\")\n",
        "\n",
        "# === Run for both STATIC and FULL ===\n",
        "fit_and_save_state_scaler(\n",
        "  df=df_A,\n",
        "  feature_list=features_static,\n",
        "  preprocessor=preprocessor_A,\n",
        "  classifier=classifier_A,\n",
        "  scaler_save_path=SCALER_STATIC_PATH,\n",
        "  label=\"STATIC\"\n",
        ")\n",
        "\n",
        "fit_and_save_state_scaler(\n",
        "  df=df_B,\n",
        "  feature_list=features_full,\n",
        "  preprocessor=preprocessor_B,\n",
        "  classifier=classifier_B,\n",
        "  scaler_save_path=SCALER_FULL_PATH,\n",
        "  label=\"FULL\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YpFsSsDKHkpS",
        "FuB47us_H82Z",
        "MhsyAS9zPGkJ",
        "b_yuq5z4PIUi",
        "BF3pKvsg7l_Q",
        "goM7lFR0Imor",
        "pK4vLTdh-jtn",
        "RZkWHMGF-ooO",
        "YAaHbPXJeX-F",
        "0ncnEtFlPSef",
        "JP5SitwkeZqA",
        "dVY8uEdKSsuQ",
        "Kc_C8J2Rk3Lg",
        "5avPC2D4TqGY",
        "3fzXTU_leM72"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
